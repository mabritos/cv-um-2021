{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "Evaluate Face Recognition.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nicolasrondan/cv-um-2021/blob/main/trabajo-final/Evaluate_Face_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsZ16Xp8LuyY",
        "outputId": "a11a89e0-8f20-4dd7-fc30-61ce2b9a8d8a"
      },
      "source": [
        "#@title \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnLZw_MSMBP0",
        "outputId": "e1efbd26-c754-48c4-a4c4-e55acabd2455"
      },
      "source": [
        "%cd /content/drive/MyDrive/computer-vision-um/cv-um-2021/trabajo-final/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/computer-vision-um/cv-um-2021/trabajo-final\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3Vu04iwJIY6"
      },
      "source": [
        "import cv2 \n",
        "import numpy as np\n",
        "import os\n",
        "import sklearn \n",
        "import sklearn.neighbors\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import sys\n",
        "import scipy.io\n",
        "from sklearn.svm import SVC\n",
        "from enum import Enum\n",
        "from skimage import feature"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-pJ5QvTJIY9"
      },
      "source": [
        "testin_data_file = './test_files/data/face_recognition/face_recognition_data_te.mat'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fReSawFJIY-"
      },
      "source": [
        "testing_data_mat = scipy.io.loadmat(testin_data_file)\n",
        "testing_data = testing_data_mat['va_img_sample']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wj3uKtysUoAR"
      },
      "source": [
        "### Feature Extraction code -> Put your own feature extractor!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Fq69VVlMgQf"
      },
      "source": [
        "class FeatureExtractors(Enum):\n",
        "\t\tMiniImage = 1\n",
        "\t\tHOG = 2\n",
        "\t\tLBP = 3\n",
        "\n",
        "def extract_features(method, img):\n",
        "\t'''Switch between Feature extraction Methods'''\n",
        "\n",
        "\timage_representation = []\n",
        "\n",
        "\tif method == FeatureExtractors.MiniImage:\n",
        "\t\timage_representation = extract_mini_image_features(img)\n",
        "\telif method == FeatureExtractors.HOG:\n",
        "\t\timage_representation = extract_hog_features(img)\n",
        "\telif method == FeatureExtractors.LBP:\n",
        "\t\timage_representation = extract_lbp_features(img)\t\n",
        "\t\n",
        "\treturn image_representation\n",
        "\n",
        "def extract_mini_image_features(img,resize_size=(64,64)):\n",
        "\tresized_image = cv2.resize(img,resize_size)\n",
        "\timage_representation = resized_image.reshape(resize_size[0]*resize_size[1])\n",
        "\treturn image_representation\n",
        "  \n",
        "def extract_lbp_features(img):\n",
        "  return []\n",
        "\n",
        "def extract_hog_features(img):\n",
        "  return []\n",
        "\n",
        "\n",
        "   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmAT1d4oJIY-"
      },
      "source": [
        "testing_images = []\n",
        "testing_labels = []\n",
        "testing_names = []\n",
        "for testing_image in testing_data:\n",
        "    image = (testing_image[0]/255)\n",
        "    label = testing_image[2] \n",
        "    name = testing_image[1][0].split('.')[0]\n",
        "    features = extract_hog_features(image)\n",
        "    #validation_images.append(image.reshape(64*64))\n",
        "    testing_images.append(features)\n",
        "    testing_labels.append(label.reshape(1))\n",
        "    testing_names.append(name)\n",
        "\n",
        "testing_images = np.asarray(testing_images)\n",
        "testing_labels = np.asarray(testing_labels)\n",
        "testing_labels = testing_labels.reshape(testing_labels.shape[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YjAigJ5JIY_"
      },
      "source": [
        "classifier = pickle.load(open('./face_recognition_svc','rb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysHyC6SvJIY_"
      },
      "source": [
        "labels = classifier.predict(testing_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CS8zZVduJIZA",
        "outputId": "f661a39d-9404-4536-fb4a-c9b687993552"
      },
      "source": [
        "acc = np.mean(labels==testing_labels)*100\n",
        "print('The accuracy of face recognition is:%.2f \\n' % acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy of face recognition is:47.06 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}